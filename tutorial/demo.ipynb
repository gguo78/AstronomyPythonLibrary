{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependency libraries\n",
    "!pip install pytest-cov \n",
    "!pip install pytest\n",
    "!pip install torch \n",
    "!pip install astroquery \n",
    "!pip install astropy\n",
    "!pip install scipy\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install our library\n",
    "!pip install -i https://test.pypi.org/simple/ skywalker-team23==0.0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skywalker_team23.data_retrieval import GetData\n",
    "from skywalker_team23.preprocessing import CleanSpectralData\n",
    "from skywalker_team23.data_augmentation import DataAugmentation\n",
    "from skywalker_team23.cross_match import CrossMatch_Gaia\n",
    "from skywalker_team23.classification import SpectralClassifier\n",
    "from skywalker_team23.visualization import SpectralVisualizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of Data_retrieval and Cross_matching"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the GetData module to query the SDSS and download data. The retrieve_sdss_data method will download the fluxes and also return the metadata like class, ra, dec, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_retriever = GetData()\n",
    "df = data_retriever.retrieve_sdss_data(\n",
    "    sql_query=\"\"\"\n",
    "                SELECT TOP 20 s.fiberid, s.plate, s.mjd, s.run2d, s.class\n",
    "                FROM PhotoObj AS p\n",
    "                JOIN SpecObj AS s ON s.bestobjid = p.objid\n",
    "                \"\"\"\n",
    ")\n",
    "#df.to_csv(\"demo_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user can also pass in custom queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_retriever.execute_custom_query(\"\"\"SELECT TOP 10 objID FROM PhotoObj AS p\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this dataframe, we can also crossmatch the sky patch with Gaia using the corss_match module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatch = CrossMatch_Gaia()\n",
    "\n",
    "# Get the ra and dec from GetData in the SDSS database\n",
    "target_ra = df[\"ra\"][1]\n",
    "target_dec = df[\"dec\"][1]\n",
    "angular_range=20\n",
    "\n",
    "# lookup for Gaia source ids that are within a certain angular distance\n",
    "print(f\"target ra: {target_ra}, target dec: {target_dec}\")\n",
    "match_df, source_ids = xmatch.match_coords(target_ra, target_dec, angular_range)\n",
    "display(match_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use those matches to get relevent astrophysical parameters from Gaia matching that part of the sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "astro_params = xmatch.get_astrophysical_params(source_ids)\n",
    "display(astro_params)\n",
    "\n",
    "ceph_params = xmatch.get_cepheid_star_param(source_ids)\n",
    "display(ceph_params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo of pairing with preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this data useful, we call the preprocessing module. It converts the raw data query dataframe into a dataframe that is more easily used for computational work. This pipeline is used in the backbone of the classifier code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the module can be initiated with the retrieved data or with a path to a saved csv file. Here I just show using the data\n",
    "cleaned_data = CleanSpectralData(dataframe=df)\n",
    "\n",
    "# First lets get the initial data that is aligned and reformatted but not edited in other ways\n",
    "_ = cleaned_data.align_wavelengths(num_wl = 1000)\n",
    "# alignemnt can also be done calling\n",
    "#lam = np.linspace(4000, 6000, 100)\n",
    "#cleaned_data.interpolate_flux(lam)\n",
    "\n",
    "init_data = cleaned_data.data.copy()\n",
    "init_lam = init_data[\"lam\"]\n",
    "init_flux = init_data[\"flux\"]\n",
    "\n",
    "# We can call to remove outliers by the IQR method\n",
    "data2 = cleaned_data.remove_flux_outliers_iqr().copy()\n",
    "lam2 = data2[\"lam\"]\n",
    "flux2 = data2[\"flux\"]\n",
    "\n",
    "# And we can apply a redshift correction \n",
    "data3 = cleaned_data.correct_redshift()\n",
    "lam3 = data3[\"lam\"]\n",
    "flux3 = data3[\"flux\"]\n",
    "\n",
    "# We can also get the normalized flux and an inferred continuum\n",
    "normalized_fluxes = cleaned_data.get_normalize_flux(update_df=True)\n",
    "inferred_cont = cleaned_data.get_inferred_continuum()\n",
    "\n",
    "fig, ax = plt.subplots(1,5, figsize=(20, 4))\n",
    "for i in range(2):\n",
    "    ax[0].plot(init_lam[i], init_flux[i], '-')\n",
    "    ax[1].plot(lam2[i], flux2[i], '-')\n",
    "    ax[2].plot(lam3[i], flux3[i], '-')\n",
    "    ax[3].plot(lam3[i], normalized_fluxes[i], '-')\n",
    "    ax[4].plot(lam3[i], inferred_cont[i], '-')\n",
    "\n",
    "titles = [\"Initial data algned\", \"Remove outliers\", \"redshift corrected\", \"normalized\", \"inferred continuum (norm)\"]\n",
    "for i, axi in enumerate(ax.flatten()):\n",
    "    axi.set_xlabel(\"Wavelength 1/A\")\n",
    "    axi.set_title(titles[i])\n",
    "ax[0].set_ylabel('10$^{-17}$ ergs/cm$^2$/s/\\AA')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module for classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the classification module to distinguish between Stars, Galaxies, and QSOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to want more data so lets load more \n",
    "# The classifier can query the data on its own like:\n",
    "classifier = SpectralClassifier(datapath=None, num_spectra=10, num_wl=500, classifier_layers=[32, 32])\n",
    "\n",
    "# but instead its better to load a large preloaded cs\n",
    "classifier = SpectralClassifier(datapath=\"./demo_data.csv\", num_spectra=10, num_wl=500, classifier_layers=[32, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the classifier fit function\n",
    "classifier.train(epochs=100,verbose=True)\n",
    "classifier.plot_train_accuracy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the predict module on some new data\n",
    "# Load some real spectra instead of making up curves\n",
    "data_retriever = GetData()\n",
    "load_num_spec = 20\n",
    "df = data_retriever.retrieve_sdss_data(\n",
    "    sql_query=f\"\"\"\n",
    "        SELECT TOP {load_num_spec} s.fiberid, s.plate, s.mjd, s.run2d, s.class\n",
    "        FROM PhotoObj AS p\n",
    "        JOIN SpecObj AS s ON s.bestobjid = p.objid\n",
    "        \"\"\"\n",
    ")\n",
    "lam = df[\"lam\"].values\n",
    "flux = df[\"flux\"].values\n",
    "\n",
    "prob, predicted_label = classifier.transform_predict(lam, flux)\n",
    "print(\"Predicted Labels: \", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = df[\"class\"].values\n",
    "print(\"Correct Prediction Boolean: \", [ predicted_label[i]==true_labels[i] for i in range(len(predicted_label))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module for Data Augmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we present the data augmentation module that is able to compute derivatives as well as fractional derivatives and append them to each preprocessed spectra. These new features can be used for future analysis on spectral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataAugmentation\n",
    "augmentor = DataAugmentation(dataframe=cleaned_data.data)\n",
    "augmentor.process_data()\n",
    "augmented_data = augmentor.data\n",
    "\n",
    "# Print out the data frame after augmentation\n",
    "augmented_data.head()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module for visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we show that the visualization module can create an interactive module to enable users to select plot regions and quantify the flux of spectral lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "visualizer = SpectralVisualizer(dataframe=augmented_data)\n",
    "visualizer.plot_spectral_visualization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
